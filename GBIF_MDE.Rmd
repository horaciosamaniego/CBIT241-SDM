---
title: "Nicho y MDE"
author: "Horacio Samaniego (horacio.samaniego@gmail.com)"
date: "`r Sys.Date()`"
output: 
  html_document: 
    toc: true
    highlight: espresso
    theme: readable
    fig_caption: true
    number_sections: true
    df_print: tibble
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
#	message = FALSE,
#	warning = FALSE,
	cache = FALSE,
	tidy = TRUE,
	tidy.opts = list(blank = FALSE, width.cutoff = 80)
)

require(pacman)
pacman::p_load(rgbif,
               rworldxtra,
               sf , 
               terra, 
               ggplot2,
               tidyverse, 
               kableExtra, 
               mapview, 
               geodata,
               ggcorrplot,
               curl)

# # For dev version
# # install.packages("devtools")
# devtools::install_github("haozhu233/kableExtra")

options("kableExtra.html.bsTable" = T)
```

# Registros de ocurrencia

## GBIF

[GBIF](https://www.gbif.org) es la Global Biodiversity Information
Facility. Una red de infraestructura de datos internacional financiada
por distintos gobiernos. Su objetivo es proporcionar acceso libre y
gratuito a datos sobre biodiversidad a nivel mundial. GBIF movilizan
datos de diversas fuentes incluyendo museos, herbarios, instituciones de
investigación y ciudadanos científicos para ponerlos a disposición del
la comunidad en un único portal. Las principales características y
funciones de GBIF incluyen: - Agregación de datos: GBIF agrega datos
sobre biodiversidad de diversas instituciones y organizaciones, creando
un conjunto de datos completo e interoperable. - Accesibilidad a los
datos: GBIF proporciona una plataforma para que los usuarios accedan a
una gran cantidad de datos sobre biodiversidad. Los investigadores, los
responsables políticos y el público en general pueden utilizar la
información para diversos fines, como la investigación científica,
planificación de la conservación y la toma de decisiones. - Estándares
de datos: GBIF promueve el uso de estándares comunes para los datos de
biodiversidad, asegurando que la información de diferentes fuentes pueda
ser fácilmente integrada y comparada. - Colaboración Internacional: GBIF
fomenta la colaboración entre países y organizaciones para compartir
datos sobre biodiversidad a nivel mundial. Funciona como una red de
nodos, cada uno de los cuales representa a un país o región. -
Informática de la Biodiversidad: GBIF desempeña un papel en el avance de
la informática de la biodiversidad, que implica el uso de tecnología
informática para gestionar y analizar datos de biodiversidad.

Al proporcionar una plataforma unificada para acceder a los datos de
biodiversidad, GBIF contribuye a la comprensión global de los patrones
de biodiversidad, ayuda a controlar los cambios en los ecosistemas y
apoya los esfuerzos relacionados con la conservación y el desarrollo
sostenible. Investigadores y responsables políticos confían a menudo en
GBIF para acceder a información actualizada y completa sobre
biodiversidad para su trabajo.

Existen además distintas API orientadas a distintos lenguajes
informáticos para acceder a esta información. (i.e.
[Ruby](https://github.com/sckott/gbifrb),
[Python](https://github.com/gbif/pygbif),
[PHP](https://gitlab.res-telae.cat/restelae/php-gbif) y
[R](https://github.com/ropensci/rgbif)). Aquí utilizaremos R para poder
acceder a datos de GBIF como parte de la practica de hacer [ciencia
abierta](https://ropensci.org/).

## Registros de ocurrencia para modelar la distribución de especies

Vamos a hacer un modelo de distribucion de especies para *Cyanoliseus
patagonus*.

-   [Descripción](https://www.avesdechile.cl/059.htm) del loro tricahue.

-   [Ficha](https://especies.mma.gob.cl/CNMWeb/Web/WebCiudadana/ficha_indepen.aspx?EspecieId=4&Version=1)
    del Ministerio del Medio Ambiente para esta especie.

**¿Cuántos registros hay para Chile?**

La función `occ_count()` retorna la cantidad de registros de presencia
de acuerdo con criterios como código del taxón (taxonKey), tipo de
registro (basisOfRecord), país y año, entre otros.

Por ejemplo, `occ_count()` retorna `r occ_count()`, el número total de
registros en la base de datos.

Ahora, `occ_count()` acepta una variedad de parámetros (ver
`?occ_count`) como por ejemplo, el conteo de registros georreferenciados
o bien el número de registros por país. Chile en este caso.

```{r ej-gbif-chile, echo=TRUE, warning=FALSE}

## Número de registros totales con georeferencia para Chile
occ_count(country="CL",hasCoordinate = TRUE, hasGeospatialIssue=FALSE)
```

Un ejemplo: ¿Cuántos registros georeferenciado de tricahue (*Cyanoliseus
patagonus*) existen en GBIF?

```{r tricahue-en-gbif, echo=TRUE}
name <- name_backbone(name='Cyanoliseus patagonus', rank='species') # Obtención del código del taxón

print(name[, c('usageKey', 'scientificName')])
```

Usando el número de registro para *Cyanoliseus patagonus* en la Base de
datos GBIF podemos contarlos:

```{r tricahue-n-cl, echo=TRUE, warning=FALSE}
p_en_cl <- occ_count(taxonKey = 2479529, 
          country = 'CL',
          hasCoordinate = TRUE, 
          hasGeospatialIssue=FALSE
)
```

Hay entonces, `r p_en_cl` registros georeferenciados en Chile en la base
de datos de GBIF!

-   [Aqui](https://docs.ropensci.org/rgbif/articles/taxonomic_names.html)
    una guía para trabajar con nombres taxonómicos.

### El loro tricahue (*Cyanoliseus patagonus*)

Ahora, podemos describir la distribución de *Cyanoliseus patagonus*.

![*Cyanoliseus patagonus* (Molina,
1782)](Cyanoliseus_patagonus_-Limari_Province,_Chile_-three-8_(cropped).jpg)

Usaremos dos funciones de la librería `rgbif` para descargar los
registros georeferenciados de tricahue en Chile. Con `occ_search()` y
`occ_data()` puedes recuperar esto y obtener todos los registros
existentes. Entre ellos, nos interesará el *nombre científico*, *país*,
*continente*, *fecha*, entre otros datos.

`occ_search` nos da un resumen de resultados como los del paquete
`dplyr` de Tidyverse que nos será muy útil para filtrar, seleccionar y
agrupar los registros, mientras que `occ_data` está optimizada para ser
más eficiente y se recomienda en caso de buscar un volumen mayor de
información desde GBIF.

-   Ojo -\> Por defecto, sólo se entrega **máximo de 100000** registros
    en cada llamada.
-   Mas info
    [aqui](https://docs.ropensci.org/rgbif/articles/getting_occurrence_data.html)
    para descargas de datos.

```{r tricahue-chile, echo=TRUE}
spp ="Cyanoliseus patagonus"
cp <- occ_data(
  scientificName = spp, 
  country = 'CL', 
  limit = 1e6, # define tope de un millón de registros
  hasCoordinate = TRUE, 
  hasGeospatialIssue = FALSE
)

print(dim(cp$data)) # dimensiones del set de datos

```

Al bajar los datos de GBIF, creamos el objeto `cp` que tiene los datos
en `cp$data`.

Vemos (con: `dim(cp$data)`) que la consulta nos retornó
`r nrow(cp$data)` registros (filas) y `r ncol(cp$data)` columnas de
información para cada registro. Esos son muchos registros. Debemos
evaluar qué son y ver cuales nos son útiles!!!

Lista completa de columnas que tiene este objeto. *i.e.* Veamos la lista
de nombres de columnas con `names()`:

```{r cols-tricahue-gbif-chile, echo=TRUE}
names(cp$data) |>
  kbl() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                fixed_thead = T) |>
  scroll_box(width = "100%", height = "350px")
```

Puedes obtener una descripción de la metadata directamente de
<http://www.gbif.org>, o en [este
documento](https://www.gbif.org/sites/default/files/gbif_resource/resource-80640/gbif_metadata_profile_guide_en_v1.pdf "Definiciones de campos de datos GBIF").

Parece que los datos de localidades están en la columns
`` `municipality` ``. Podemos entonces, de la misma manera, ver en que
localidades ocurrieron los muestreos. El comando `unique()` muestra los
valores únicos en el vector/columna `cp$data$locality`:

```{r localities, echo=TRUE}
unique(cp$data$municipality) |>
  kbl() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),fixed_thead = T) |>
  scroll_box(width = "100%")
```

## Construcción de un set de datos geográfico

Cada registro tiene asociado coordenadas geográficas, lo que nos permite
transformar esta tabla a un objeto de tipo `sf` ([simple
feature](https://r-spatial.github.io/sf/articles/sf1.html)). Con eso
podemos representarlo espacialmente.

Primero transformamos estos datos en un objeto "geográfico" de `sf`
usando las columnas `"decimalLongitude"` para `x` y `"decimalLatitude"`
para `y`. Hay que tambien designar la proyección geográfico. Aqui es
simplemente la latlon ([epsg: 4326](https://epsg.io/4326)).

-   [Aquí](https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf)
    una guía básica para comprender proyecciones geográficas de
    [NCEAS](https://www.nceas.ucsb.edu/).

```{r tricahue-sf, echo=TRUE}
cp_sf <- st_as_sf(cp$data, coords = c("decimalLongitude", "decimalLatitude"), 
                   crs= "epsg:4326")
```

ahora, veamos nuevamente las primeras 20 filas de la tabla :

```{r ver-tabla-tricahue-gbif, echo=FALSE}
# mostramos las primeras 20 lineas
cp_sf[1:20,] |>
  kbl() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) |>
  scroll_box(width = "100%", height = "400px")

# cp_sf[1:20,] # hace lo ismo que arriba, pero sin la libreria kblExtra

```

es básicamente la misma que `cp`, la anterior, sólo que se puede
manipular espacialente y tiene una columna llamada `geometry`. Esto nos
permite manipular los datos como si cada fila fuera un punto a ver en un
mapa pues cada registro (fila) tiene asociada una coordenada.

### Distribución geográfica de registros de C.patagonus en GBIF para Chile

Lo primero es ver donde quedan estas coordenadas. Usaremos `ggplot2`.

Pero, es posible poner los registros en un mapa de las comunas de Chile?

Para eso necesitamos un mapa de las comunas. Buscamos entre los
shapefiles de la Biblioteca Nacional y lo usamos como mapa base.

```{r leer-shp-bcn, echo=TRUE}
shp='comunas.shp'

if ( !file.exists(shp) ){
  url_com = "https://www.bcn.cl/obtienearchivo?id=repositorio/10221/10396/2/Comunas.zip"
  print(paste("Descargando",shp, "de",url_com))
  # library(curl)
  com_tmp = tempfile()
  com = curl::curl_download(url_com,com_tmp)
  unzip(com)
}

comunas = read_sf("comunas.shp") |>
  dplyr::select(Comuna, Provincia) |>
  st_transform(crs=32719) # es importante manejar esa info en coordenadas "reales"
cp_sf2 <- cp_sf |>
  st_transform(crs=32719) # es importante manejar esa info en coordenadas "reales"
# rm(cp_sf) # borramos mapa en latlon para ahorrar memoria

ggplot() + 
  geom_sf(data=comunas, alpha=.1) +
    geom_sf(data = cp_sf2, pch=4, col="purple") + theme_bw() +
   ggtitle("Registros de C. patagonus en GBIF")  +
    # ylim(st_bbox(cp_sf2)[2]-5e4,st_bbox(cp_sf2)[4]+5e4) +
    ylim(st_bbox(cp_sf2)[2]+1.05e6,st_bbox(cp_sf2)[4]-5.5e5) +
    xlim(st_bbox(cp_sf2)[1]-2.5e5,st_bbox(cp_sf2)[3]+5e4) # ajustar
```

podemos hacer un zoom limitando el `x` e `y` a mostrar con `ylim` y
`xlim`. Para eso usamos `st_bbox()` que retorna la extensión del objeto
geográfico. Noten las diferencias entre los objetos.

```{r extension-pountos1, echo=TRUE}
# con esto vemos los limites geograficos al obj
print('cp_sf:')
print(st_bbox(cp_sf))
```

Aqui el reproyectado a UTM 19S:
```{r extension-pountos2, echo=TRUE}
print('cp_sf2:')
print(st_bbox(cp_sf2))

# borrar el primero para liberar memoria
rm(cp_sf)
```

Como veremos en el próximo, hay 2 núcleos principales (¿poblaciones?) y
algunos puntos que representan, probablemente, errores de avistamiento.
OjO: Debieramos removerlos antes del análisis.

### Visualización interactiva

Podemos usar la librería
[mapview](https://r-spatial.github.io/mapview/ "librería para R") para
explorar los datos de forma interactiva, usando la columna `year`, por
ejemplo, si queremos ver cómo se ha muestreado a través de los años.
Usaremos el parámetro `cex` para ajustar el tamaño del marcador (punto)
que nos permite visualizar el número de registros por año.

Creamos primero una tabla (`conteo`) que resume el número de
avistamientos por localidad y se lo agregamos a una columna llamada
'Número de registros'. Fíjate en el uso de `group_by()`, `mutate()` y
`distinct()`. Son funciones de `dplyr` que en su conjunto agrupan por
punto de muestreo, luego crea (con `mutate()`) una columna donde
almacena el número de registros distintos.

```{r ploteo-interactivo, echo=TRUE}

cp_sf2 <- cp_sf2 |> 
  filter(!st_is_longlat(geometry)) |>
    mutate('lon'=st_coordinates(st_transform(geometry,'EPSG:4326'))[,1], 
         'lat'=st_coordinates(st_transform(geometry,'EPSG:4326'))[,2]) 

conteo <- cp_sf2 |>
  group_by(geometry) |>
  dplyr::select(key,stateProvince,locality,day, month,year,recordedBy,lon,lat) |>
  mutate('Número de registros'=n()) |>
  distinct()|>
  st_as_sf()
```

Ahora, la nueva table `conteo` tiene el mismo número de filas que
`cp_sf2`, lo que nos indica que hay realmente un solo registro por fila.

Con esto vemos solo las columnas indicadas por `select()` Vamos a

```{r conteo-tricaue, echo=TRUE}
filas = 15 # vamos a muestrear n numero de filas para mostrar.  
conteo[sample(1:nrow(conteo),size=filas),] |>
  kbl() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) |>
  scroll_box(width = "100%", height = "400px")
```


### Ploteo interactivo con MapView

Permite ver los datos en un contexto geográfico web. Podemos también
ajustar el tamaño de los puntos según valor de la columna de los números
de registros, separados por la categoría de año (columna `year`).

```{r ploteo-interactivo2, echo=TRUE}
mapview(conteo,zcol='year',cex="Número de registros", alpha=.35, layer.name='Año')
```


### Limpieza de datos

Este paso consiste en limpiar los datos que nos parecen espurios, pues asemejan mas a un error de identificación, o ingreso de datos,  que a registros reales de la especie. 

Para eso vamos a:
1. eliminar las ocurrencias extremas
2. marcar cada registro de ocurrencia en dos grupos:
  a. los del norte, y 
  b. los del sur. 

Una vez que evaluamos los limites 
```{r}
lim_norte = -28.715
lim_sur = -36.24
lim_sur_grupo_norte = -31.006
lim_norte_grupo_sur = -33.34
lim_oeste_grupo_sur = -71.8

cp_sf2 <- cp_sf2 |>
  mutate(Grupo = case_when(
    lat > lim_sur_grupo_norte & lat < lim_norte ~ 'Norte',
    lat < lim_norte_grupo_sur & lat > lim_sur & lon > lim_oeste_grupo_sur ~ 'Sur'
    ))
```
Veamos como quedó
```{r plot-groups,echo=FALSE}
mapview(cp_sf2,zcol='Grupo', alpha=.35, layer.name='Grupo')

```

  

## Nicho climático

Vamos a buscar cuáles son las condiciones climáticas en que están estos
registros para generar asi, una definición (gruesa) del nicho climático
para Tricahue.

Usaremos los datos de Worldclim, que se encuentran documentados
[aquí](https://www.worldclim.org). Sólo usaremos las variables
bioclimáticas, en este ejemplo, pero debes complementar esto con
variables de precipitaciones, temperatura y radiación solar si fuera
necesario.

-   Ojo: La función `worldclim_country()` de la librería `geodata`
    permite descargar directamente desde worldclim los datos
    bioclimáticos por paises. Worlclim ofrece sus datos en 4
    resoluciones espaciales diferentes; de 30 segundos (0,93 x 0,93 =
    0,86 km2 en el ecuador) a 2,5, 5 y 10 minutos (18,6 x 18,6 = 344 km2
    en el ecuador). Los datos originales tenían una resolución de 30
    segundos. También ofrece datos climáticos de distintas proyecciones
    de cambio climático futuro (CMIP5) del modelo 'AC' para el año 2070,
    por ejemplo.\

```{r worldclim, echo=TRUE}

Bioclim <- worldclim_country(c("Chile","Argentina"), 
                             var=c("bio"), res=0.5, path=getwd()) |>
  terra::crop(st_transform(cp_sf2,'EPSG:4326')) # reproyectamos 'al vuelo', pues bioclim viene en epsg:4326

names(Bioclim) <- sapply(strsplit(names(Bioclim), split='30s_', fixed=TRUE), function(x) (x[2])) # renombra columnas
names(Bioclim) <- sapply(gsub('_','',names(Bioclim)), function(x) (x))


plot(Bioclim)
```

### Clima en registros de *C. patagonus*

Para extraer los datos bioclimáticos en las coordenadas geográficas,
debemos consultar los pixeles de los rasters bioclimáticos donde existen
ocurrencias en nuestra bas de datos.

![Ejemplo de consulta de valores de raster en
coordenadas](https://www.esri.com/arcgis-blog/wp-content/uploads/2018/08/extraction_multi.jpg)

La función a usar está en la librería `raster` y se llama `extract()`.

Con eso generamos una tabla con las variables climáticas en cada una de
las coordenadas en que tenemos registros.

```{r extraccion-datos-bioclimaticos, echo=TRUE}
Clima <- raster::extract(Bioclim, st_transform(cp_sf2,'EPSG:4326'))
Clima <- Clima[,-1]
```

Vemos la tabla con los datos bioclimáticos para cada registro. *(filas =
primero 15 registros)*

```{r extract, echo=FALSE}
Clima |>
  slice(1:filas) |>
  kable() |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed")) |>
  scroll_box(width = "100%", height = "400px")
```

Ahora, a qué corresponde bio1, bio2, etc...??

Veamos, por una parte, qué son estas variables:
`r knitr::include_url("https://www.worldclim.org/data/bioclim.html", height="400px")`

Por otra parte, la inspección de la tabla muestra que sólo tiene los
valores bioclimáticos. Necesitamos, ciertamente, asociar los registros y
probablemente otros datos climáticos como temperatura, precipitaciones,
radiación, por ejemplo.

Pero miremos primero cómo se relacionan los valores bioclimáticos
recuperados para GBIF tiene registros de *C. patagonus* en Chile.

### Selección de vaiables (bioclimáticas)

Sabemos que las variables bioclimáticas son variables derivadas de la
variables de clima. Por lo tanto, han de tener **fuertes correlaciones
entre ellas**. La pregunta es cuales elegir y minimizar asi, esta
correlación espuria que sólo incrementará el ajuste del modelo de forma
artificial.

-   [Ver aqui](https://www.worldclim.org/data/bioclim.html) la
    descripción de las variable bioclimáticas de worldclim.
    

A continuación se describen las 19 variables bioclimáticas:
- bio1 = Temperatura media anual
- bio2 = amplitud diurna media (media de la temperatura máxima y mínima)
- bio3 = Isotermia (bio2/bio7) (* 100)
- bio4 = Estacionalidad de la temperatura (desviación típica *100)
- bio5 = Temperatura máxima del mes más cálido
- bio6 = Temperatura mínima del mes más frío
- bio7 = Rango anual de temperaturas (bio5-bio6)
- bio8 = Temperatura media del trimestre más húmedo
- bio9 = Temperatura media del trimestre más seco
- bio10 = Temperatura media del trimestre más cálido
- bio11 = Temperatura media del trimestre más frío
- bio12 = Precipitación total (anual)
- bio13 = Precipitación del mes más húmedo
- bio14 = Precipitación del mes más seco
- bio15 = Estacionalidad de las precipitaciones (coeficiente de variación)
- bio16 = Precipitación del trimestre más húmedo
- bio17 = Precipitaciones del trimestre más seco
- bio18 = Precipitaciones del trimestre más cálido
- bio19 = Precipitaciones del trimestre más frío

Buscamos comprender cuáles variables bioclimáticas son
significativamente relevantes para describir, y predecir, la
distribución de la especies. Esto significa que debemos poder tener una
variables que representan, en realidad, un mismo aspecto del clima a la
hora de generar una predicción.

Veamos la correlación entre la variables bioclimáticas donde hay *C.
patagonus*. Fíjense que se han agrupados las filas y columnas con
correlaciones similares para facilitar la interpretación. Eso puede
hacerse con la librería `ggcorrplot` y su parámetro `hc.order`.

```{r tabla-correlaciones-bioclimaticas, echo=TRUE}

# install.packages("ggcorrplot")
# library(ggcorrplot)
p_load(ggcorrplot)

corr <- cor(Clima[,-1],use = "pairwise") # ojo que removemos la primera columna que es el 'ID'
ggcorrplot::ggcorrplot(corr,method='circle',pch=2,show.diag = FALSE,type="upper",
           ggtheme = theme_minimal(),hc.order = TRUE)
```

Seleccionamos entonces algunas variables de *Bioclim* que muestren baja
correlación (no negativa!).

yo veo las variables :

-   BIO?? = XXX
-   BIO?? = XXX
-   BIO?? = XXX
-   BIO?? = XXX
-   BIO?? = XXX

(son todas de temperatura?.... mmmh sus. Creo que será importante
considerar directamente las variables climáticas.)

```{r sel-vars-bioclimaticas, echo=TRUE}
## ejemplo con algunas variables... que no son las correctas, pero muestra el procedimiento
Var_ambientales <- Clima|>
  dplyr::select(bio1,bio3,bio5,bio9,bio10)

# rm(Bioclim,Clima) # borramos para aliviar la memoria del compu!
```



# Modelos de distribución de especies

## Pseudo-ausencias (i.e. no-avistamientos)

Necesitamos generar datos de pseudo-ausencias para evaluar sitios donde no se ha encontrado tricahue. Para eso generaremos  puntos aleatorios en la misma cantidad de ocurrencias descargadas de GBIF.

Luego, combinamos con los datos de variables climáticas obtenidas para generar un objeto con todas las variables climáticaspara los sitios de presencias y de preudo-ausencias.
```{r}
p_load(dismo)

# setting random seed to always create the same
# random set of points for this example
set.seed(69) 

backgr <- randomPoints(raster::stack(Bioclim), nrow(Clima))
pseudo_ausencias <- raster::extract(Bioclim,backgr)

presencias <- c(rep(1, nrow(pseudo_ausencias)), rep(0, nrow(Clima)))
mde_data <- data.frame(cbind(presencias, rbind(pseudo_ausencias, Clima)))

```


## GLM
### Ajustar modelo


```{r glm, echo=TRUE}
m1 <- step(glm(presencias ~ . , data=mde_data, family = binomial(link = "logit")),trace=0)
summary(m1)
```
### Predicción

Con el modelo podemos generar 

```{r glm-prediccion, echo=TRUE}
predictions <- predict(Bioclim, m1, type = "response")

plot(predictions, colNA='black')


```
### Evaluación

Podemos mirar el Area Bajo la Curva

```{r}
presence_data = filter(mde_data, presencias == 1)
absence_data = filter(mde_data, presencias == 0)

evaluation <- evaluate(presence_data, absence_data, m1)
tr <- threshold(evaluation, 'spec_sens')

plot(evaluation, 'ROC')
```
### Umbrales de distribución

```{r}
thresh <- threshold(evaluation, stat = 'prevalence')
thresh <- threshold(evaluation, 'spec_sens')
plot(predictions > thresh)#, ext = extent(-140, -50, 25, 60))
# points(present, pch='+', cex = 0.5)

```

## Random Forest

## Evaluación de modelo

[Fieldings et al
1997](https://www.dropbox.com/scl/fi/s9a0e56osliczbl3csuhg/Fielding_Bell_1997_A-review-of-methods-for-the-assessment-of-prediction-errors-in-conservation.pdf?rlkey=n1iib2m1dcgpc7ad81ykdy3np&dl=0)
\### La matriz de confusión

### data splitting

## Reporte

Con estos ejercicios iremos haciendo un reporte, que será entregado el
18 de nunio 2024.

### Descripción de datos y análisis preliminar

### Mapeo y representación gráfica

1.  Haz un mapa de la distribución de tu *C. patagus* para Chile

<!-- -->

a.  ¿En cuántas Regiones encontramos a esta especie?
b.  Remueve los "outliers". ¿En cuales comunas de Chile está ahora?

### Análisis de variables independientes

3.  Construye una base de datos (tabla), con los valores de
    *temperatura*, *pp*, *radiación* y variables bioclimáticas donde
    ocurre tu *C.patagus* en Chile.
    a.  Elige las variables mas idoneas para modelar el nicho de *C.
        patagus*. Justifica tu elección en términos de la biología de la
        especie.
4.  Describe estadisticamente el espacio bioclimático en que ocurre tu
    *especie de preferencia*

<!-- -->

a.  Rangos de T y PP, promedio, moda, desviaciones...

<!-- -->

5.  Separa los puntos de ocurrencia en 2 sets que representen las
    poblaciones disjuntas de la especie.

<!-- -->

a.  Vuelve a a hacer 3 y 4

### Análisis de distribución

5.  General 2 modelos de distribución para cada grupo de ocurrencias.
    Esto es, usa dos modelos estadísticos de tu preferencia que
    expliquen la distribución de *C. patagus* en su conjunto y los 2
    grupos de ocurrencia seleccionado en 5

<!-- -->

a.  ¿Cuál(es) es(son) la(s) variable(s) independiente(s) que mejor se
    asocian con la presencia ?
b.  Construye la matriz de confusión para los 3 grupos (el total, las
    ocurrencias del norte y las del sur)

### Predicción

6.  Indica cual es la predicción para la distribución de *C. patagus*

7.  Discute tus resultados desde las siguientes perspectivas:

<!-- -->

a.  Técnicas la construcción del modelo elegido
b.  Biológica y de conservación de tu *especie de preferencia*.
